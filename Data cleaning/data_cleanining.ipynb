{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Advanced Classification Hackathon"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Author: Stephen Mutiso\n",
    "    Date: 24 June 2023\n",
    "    Email: mutisosteve05@gmail.com\n",
    "    Position: Data Scientist\n",
    "    Company: Explore-AI\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "South Africa is a multicultural society that is characterised by its rich linguistic diversity. Language is an indispensable tool that can be used to deepen democracy and also contribute to the social, cultural, intellectual, economic and political life of the South African society.\n",
    "\n",
    "The country is multilingual with 11 official languages, each of which is guaranteed equal status. Most South Africans are multilingual and able to speak at least two or more of the official languages."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this challenge, we will take text which is in any of South Africa's 11 Official languages and identify which language the text is in. This is an example of NLP's Language Identification, the task of determining the natural language that a piece of text is written in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train_set.csv', encoding='UTF-8')\n",
    "test = pd.read_csv('test_set.csv',encoding='UTF-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang_id                                               text\n",
       "0     xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...\n",
       "1     xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...\n",
       "2     eng  the province of kwazulu-natal department of tr...\n",
       "3     nso  o netefatša gore o ba file dilo ka moka tše le...\n",
       "4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana..."
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = data.copy()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     33000\n",
       "unique       11\n",
       "top         xho\n",
       "freq       3000\n",
       "Name: lang_id, dtype: object"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.lang_id.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy['length'] = data_copy['text'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10244\\3175101911.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below removes punctuation and ASCII code character using string.punctuation function  \n",
    "Args:\n",
    "\n",
    "    data: pandas dataframe\n",
    "\n",
    "Return:\n",
    "\n",
    "    Dataframe: clean tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def punctuation_remover(x):\n",
    "    \n",
    "    x = re.sub(r'[-]',' ',x)\n",
    "    x = re.sub(r'[_]', ' ', x)\n",
    "    x = re.sub(r'[^\\w\\s]','',x)\n",
    "    x = re.sub('[0-9]+', '', x)\n",
    "    x = re.sub(r'[^\\x00-\\x7f]',r'', x)\n",
    "    return x\n",
    "\n",
    "\n",
    "#Apply the function to the dataset\n",
    "data_copy['clean_punc'] = data_copy['text'].apply(punctuation_remover)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower(x):\n",
    "\n",
    "    return x.lower()\n",
    "\n",
    "data_copy['lower'] = data_copy['clean_punc'].apply(lower)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'could not'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nlppreprocess import NLP\n",
    "nlp = NLP()\n",
    "nlp.process('couldnt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mutis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function in the code cell below removes stop-words in the dataset to reduce noise.\n",
    "\n",
    "Args:\n",
    "    data: pandas dataframe\n",
    "Return:\n",
    "    df:non-stop word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(x):\n",
    "    \n",
    "    stopwords = NLP(replace_words=True, remove_stopwords=True, \n",
    "                            remove_numbers=True, remove_punctuations=False) \n",
    "    x = stopwords.process(x)\n",
    "    return x\n",
    "    \n",
    "data_copy['Text_nonstop'] = data_copy['lower'].apply(lambda x: remove_stopwords(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyzer (x):\n",
    "    \"\"\"\n",
    "    Function combines all the cleaning operations\n",
    "    \"\"\"\n",
    "    x = punctuation_remover(x)\n",
    "    x = lower(x)\n",
    "    x = remove_stopwords(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>clean_punc</th>\n",
       "      <th>lower</th>\n",
       "      <th>Text_nonstop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "      <td>220</td>\n",
       "      <td>umgaqo siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "      <td>umgaqo siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "      <td>umgaqo siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "      <td>252</td>\n",
       "      <td>i dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "      <td>i dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "      <td>dha iya kuba nobulumko bokubeka umsebenzi naph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "      <td>264</td>\n",
       "      <td>the province of kwazulu natal department of tr...</td>\n",
       "      <td>the province of kwazulu natal department of tr...</td>\n",
       "      <td>province kwazulu natal department transport in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "      <td>217</td>\n",
       "      <td>o netefata gore o ba file dilo ka moka te le d...</td>\n",
       "      <td>o netefata gore o ba file dilo ka moka te le d...</td>\n",
       "      <td>o netefata gore o ba file dilo ka moka te le d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "      <td>239</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang_id                                               text  length  \\\n",
       "0     xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...     220   \n",
       "1     xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...     252   \n",
       "2     eng  the province of kwazulu-natal department of tr...     264   \n",
       "3     nso  o netefatša gore o ba file dilo ka moka tše le...     217   \n",
       "4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana...     239   \n",
       "\n",
       "                                          clean_punc  \\\n",
       "0  umgaqo siseko wenza amalungiselelo kumaziko ax...   \n",
       "1  i dha iya kuba nobulumko bokubeka umsebenzi na...   \n",
       "2  the province of kwazulu natal department of tr...   \n",
       "3  o netefata gore o ba file dilo ka moka te le d...   \n",
       "4  khomishini ya ndinganyiso ya mbeu yo ewa maana...   \n",
       "\n",
       "                                               lower  \\\n",
       "0  umgaqo siseko wenza amalungiselelo kumaziko ax...   \n",
       "1  i dha iya kuba nobulumko bokubeka umsebenzi na...   \n",
       "2  the province of kwazulu natal department of tr...   \n",
       "3  o netefata gore o ba file dilo ka moka te le d...   \n",
       "4  khomishini ya ndinganyiso ya mbeu yo ewa maana...   \n",
       "\n",
       "                                        Text_nonstop  \n",
       "0  umgaqo siseko wenza amalungiselelo kumaziko ax...  \n",
       "1  dha iya kuba nobulumko bokubeka umsebenzi naph...  \n",
       "2  province kwazulu natal department transport in...  \n",
       "3  o netefata gore o ba file dilo ka moka te le d...  \n",
       "4  khomishini ya ndinganyiso ya mbeu yo ewa maana...  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cleaned'] = data['text'].apply(analyzer)\n",
    "test['cleaned'] = test['text'].apply(analyzer)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting  features(X) and response(Y) variables\n",
    "X = data['cleaned']\n",
    "y = data['lang_id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train ,X_test ,y_train ,y_test = train_test_split(X , y, stratify=y,\n",
    "                                                       test_size =0.4, \n",
    "                                                       random_state=42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing relevant models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing Models from scikit-learn\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, RidgeClassifier\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [LogisticRegression(random_state =42 , max_iter=5000) , \n",
    "       MultinomialNB(), LinearSVC(random_state=42), \n",
    "       SGDClassifier(random_state=42), RidgeClassifier(random_state=42)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer , TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performace_assesment(*args , **kwargs):\n",
    "\n",
    "  model_statistics = {}\n",
    "  for clf in classifiers:\n",
    "    model = Pipeline([('tfidf', TfidfVectorizer(stop_words = 'english', max_df=0.9, ngram_range=(1, 5), analyzer= 'char')),\n",
    "                      ('clf' , clf)\n",
    "                      ])\n",
    "    \n",
    "    model.fit(X_train, y_train) #Training\n",
    "    model_pred = model.predict(X_test) #Testing\n",
    "\n",
    "    # Dictionary of Models Performances\n",
    "    model_statistics[clf.__class__.__name__] = {\n",
    "        'F1-Macro':metrics.f1_score(y_test, model_pred, average='macro'),\n",
    "        'F1-Accuracy':metrics.f1_score(y_test, model_pred, average='micro'),\n",
    "        'F1-Weighted':metrics.f1_score(y_test, model_pred, average='weighted')}\n",
    "  return pd.DataFrame.from_dict(model_statistics, orient='index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1-Macro</th>\n",
       "      <th>F1-Accuracy</th>\n",
       "      <th>F1-Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.999394</td>\n",
       "      <td>0.999394</td>\n",
       "      <td>0.999394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifier</th>\n",
       "      <td>0.999167</td>\n",
       "      <td>0.999167</td>\n",
       "      <td>0.999167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.999167</td>\n",
       "      <td>0.999167</td>\n",
       "      <td>0.999167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.999091</td>\n",
       "      <td>0.999091</td>\n",
       "      <td>0.999091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.998183</td>\n",
       "      <td>0.998182</td>\n",
       "      <td>0.998183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    F1-Macro  F1-Accuracy  F1-Weighted\n",
       "MultinomialNB       0.999394     0.999394     0.999394\n",
       "RidgeClassifier     0.999167     0.999167     0.999167\n",
       "LinearSVC           0.999167     0.999167     0.999167\n",
       "SGDClassifier       0.999091     0.999091     0.999091\n",
       "LogisticRegression  0.998183     0.998182     0.998183"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_performance = performace_assesment(classifiers , X_train , X_test , y_train , y_test)\n",
    "model_performance.to_csv('performance.csv')\n",
    "df = pd.read_csv('performance.csv', index_col = 0)\n",
    "df.sort_values('F1-Weighted', ascending=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_tuning(*args , **kwargs):\n",
    "  best_params = {}\n",
    "\n",
    "  for clf in classifiers:\n",
    "    model = Pipeline([('tfidf', TfidfVectorizer(stop_words = 'english', max_df=0.9, ngram_range=(1, 5), analyzer= 'char')),\n",
    "                      ('clf' , clf)])\n",
    "    model.fit(X_train, y_train) #Training\n",
    "    \n",
    "    #Get models performing parameters\n",
    "    params = model.get_params()\n",
    "    model_name = clf.__class__.__name__  \n",
    "    model_name = {}\n",
    "    for key in params:\n",
    "      if key.startswith(\"clf\"):\n",
    "        if len(key) < 5:\n",
    "          model_name['model'] = params[key]\n",
    "        else:\n",
    "            model_name[key[5:]] = params[key]\n",
    "    best_params[clf.__class__.__name__] = model_name\n",
    "  return best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = parameter_tuning(classifiers, X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vectorize = TfidfVectorizer(stop_words = 'english', max_df=0.9, ngram_range=(1, 5), analyzer= 'char')\n",
    "X_train = Vectorize.fit_transform(X_train)\n",
    "X_test = Vectorize.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True,\n",
    "                                   random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': MultinomialNB(),\n",
       " 'alpha': 1.0,\n",
       " 'class_prior': None,\n",
       " 'fit_prior': True}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params[classifiers[1].__class__.__name__]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = list(np.linspace(0.1,0.02,4))\n",
    "param_grid = dict(alpha=alpha)\n",
    "grid_search = GridSearchCV(estimator= model1,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='f1_weighted',\n",
    "                           cv=stratified_kfold,\n",
    "                           error_score=0,\n",
    "                           n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train)\n",
    "prediction = grid_search.predict(X_test)\n",
    "cv_score = grid_search.best_score_\n",
    "test_score = grid_search.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation score: 0.9996969686252897\n",
      "Test score: 0.9995455174533855\n"
     ]
    }
   ],
   "source": [
    "print(f'Cross-validation score: {cv_score}')\n",
    "print(f'Test score: {test_score}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling RidgeRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = RidgeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': RidgeClassifier(random_state=42),\n",
       " 'alpha': 1.0,\n",
       " 'class_weight': None,\n",
       " 'copy_X': True,\n",
       " 'fit_intercept': True,\n",
       " 'max_iter': None,\n",
       " 'normalize': 'deprecated',\n",
       " 'positive': False,\n",
       " 'random_state': 42,\n",
       " 'solver': 'auto',\n",
       " 'tol': 0.001}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params[classifiers[4].__class__.__name__]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = list(np.linspace(0.15,0.4, 5))\n",
    "param_grid = dict(alpha=alpha)\n",
    "grid_search = GridSearchCV(estimator= model2,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='f1_weighted',\n",
    "                           cv=stratified_kfold,\n",
    "                           error_score=0,\n",
    "                           n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train)\n",
    "prediction = grid_search.predict(X_test)\n",
    "cv_score = grid_search.best_score_\n",
    "test_score = grid_search.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation score: 0.9994949477404799\n",
      "Test score: 0.9990909717224429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RidgeClassifier(alpha=0.275)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Cross-validation score: {cv_score}')\n",
    "print(f'Test score: {test_score}')\n",
    "grid_search.best_params_    \n",
    "grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.pipeline import make_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['cleaned']\n",
    "y = data['lang_id']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test , y_train , y_test = train_test_split(X, y,  stratify=y, test_size=0.4, random_state =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(stop_words = 'english', max_df=0.9, ngram_range=(2, 6), analyzer= 'char')\n",
    "X_train = vect.fit_transform(X_train)\n",
    "X_test = vect.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiNB1 = MultinomialNB(alpha=0.1)\n",
    "multiNB2 = MultinomialNB(alpha=0.1)\n",
    "\n",
    "estimators = [('multiNB1', multiNB1), ('multiNB2', multiNB2)]\n",
    "final_est = RidgeClassifier(alpha=0.2125)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_NB2 = StackingClassifier(estimators = estimators,\n",
    "                           final_estimator = final_est,\n",
    "                           passthrough = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('multiNB1', MultinomialNB(alpha=0.1)),\n",
       "                               ('multiNB2', MultinomialNB(alpha=0.1))],\n",
       "                   final_estimator=RidgeClassifier(alpha=0.2125),\n",
       "                   passthrough=True)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking_NB2.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = stacking_NB2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1-Macro</th>\n",
       "      <th>F1-Accuracy</th>\n",
       "      <th>F1-Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>StackingClassifier</th>\n",
       "      <td>0.999773</td>\n",
       "      <td>0.999773</td>\n",
       "      <td>0.999773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    F1-Macro  F1-Accuracy  F1-Weighted\n",
       "StackingClassifier  0.999773     0.999773     0.999773"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_stats = {}\n",
    "model_stats[stacking_NB2.__class__.__name__] = {\n",
    "        'F1-Macro':metrics.f1_score(y_test, pred, average='macro'),\n",
    "        'F1-Accuracy':metrics.f1_score(y_test, pred, average='micro'),\n",
    "        'F1-Weighted':metrics.f1_score(y_test, pred, average='weighted')}\n",
    "pd.DataFrame.from_dict(model_stats, orient='index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer(ngram_range=(3,7), analyzer= 'char')\n",
    "X_train , X_test , y_train , y_test = train_test_split(X, y, stratify=y,test_size=0.05, random_state =1)\n",
    "X_train = count_vec.fit_transform(X_train)\n",
    "X_test = count_vec.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiNB1 = MultinomialNB(alpha=0.1)\n",
    "multiNB2 = MultinomialNB(alpha=0.1)\n",
    "multiNB3 = MultinomialNB(alpha=0.1)\n",
    "\n",
    "estimators = [('multiNB1', multiNB1), ('multiNB2', multiNB2), ('multiNB3', multiNB3)]\n",
    "final_est = RidgeClassifier(alpha=0.2125)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_NB3 = StackingClassifier(estimators = estimators,\n",
    "                           final_estimator = final_est,\n",
    "                           passthrough = True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('multiNB1', MultinomialNB(alpha=0.1)),\n",
       "                               ('multiNB2', MultinomialNB(alpha=0.1)),\n",
       "                               ('multiNB3', MultinomialNB(alpha=0.1))],\n",
       "                   final_estimator=RidgeClassifier(alpha=0.2125),\n",
       "                   passthrough=True)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking_NB3.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = stacking_NB3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1-Macro</th>\n",
       "      <th>F1-Accuracy</th>\n",
       "      <th>F1-Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>StackingClassifier</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    F1-Macro  F1-Accuracy  F1-Weighted\n",
       "StackingClassifier       1.0          1.0          1.0"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_stats = {}\n",
    "\n",
    "model_stats[stacking_NB3.__class__.__name__] = {\n",
    "        'F1-Macro':metrics.f1_score(y_test, pred, average='macro'),\n",
    "        'F1-Accuracy':metrics.f1_score(y_test, pred, average='micro'),\n",
    "        'F1-Weighted':metrics.f1_score(y_test, pred, average='weighted')}\n",
    "pd.DataFrame.from_dict(model_stats, orient='index')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = test['cleaned']\n",
    "Vectorize = vect.transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['lang_id'] = stacking_NB2.predict(Vectorize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lang_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>tsn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>nbl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ssw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>afr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5677</th>\n",
       "      <td>5678</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5678</th>\n",
       "      <td>5679</td>\n",
       "      <td>nso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5679</th>\n",
       "      <td>5680</td>\n",
       "      <td>sot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5680</th>\n",
       "      <td>5681</td>\n",
       "      <td>sot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5681</th>\n",
       "      <td>5682</td>\n",
       "      <td>nbl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5682 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index lang_id\n",
       "0         1     tsn\n",
       "1         2     nbl\n",
       "2         3     ven\n",
       "3         4     ssw\n",
       "4         5     afr\n",
       "...     ...     ...\n",
       "5677   5678     eng\n",
       "5678   5679     nso\n",
       "5679   5680     sot\n",
       "5680   5681     sot\n",
       "5681   5682     nbl\n",
       "\n",
       "[5682 rows x 2 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = test[['index', 'lang_id']]\n",
    "submission.to_csv('Submission.csv',index=False)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       mmasepala fa maemo kgethegileng letlelela kgat...\n",
       "1       uzakwaziswa ngokufaneleko nakungafuneka eminye...\n",
       "2               tshivhumbeo tshi fana na ngano dza vhathu\n",
       "3       kube inja nelikati betingevakala kutsi titsini...\n",
       "4                            winste op buitelandse valuta\n",
       "                              ...                        \n",
       "5677                      you mark your ballot in private\n",
       "5678    ge o ka kgetha ka bowena go se omie mofani ka ...\n",
       "5679    e ka kopo etsa kgetho ya hao ka hloko hobane h...\n",
       "5680    tb ke bokudi ba pmb mme morero o tla lefella t...\n",
       "5681                 vakatjhela iwebhusayidi yethu ku www\n",
       "Name: cleaned, Length: 5682, dtype: object"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
