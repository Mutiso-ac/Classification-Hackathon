{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Advanced Classification Hackathon"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Author: Stephen Mutiso\n",
    "    Date: 24 June 2023\n",
    "    Email: mutisosteve05@gmail.com\n",
    "    Position: Data Scientist\n",
    "    Company: Explore-AI\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "South Africa is a multicultural society that is characterised by its rich linguistic diversity. Language is an indispensable tool that can be used to deepen democracy and also contribute to the social, cultural, intellectual, economic and political life of the South African society.\n",
    "\n",
    "The country is multilingual with 11 official languages, each of which is guaranteed equal status. Most South Africans are multilingual and able to speak at least two or more of the official languages."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this challenge, we will take text which is in any of South Africa's 11 Official languages and identify which language the text is in. This is an example of NLP's Language Identification, the task of determining the natural language that a piece of text is written in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang_id                                               text\n",
       "0     xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...\n",
       "1     xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...\n",
       "2     eng  the province of kwazulu-natal department of tr...\n",
       "3     nso  o netefatša gore o ba file dilo ka moka tše le...\n",
       "4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train_set.csv', encoding='UTF-8')\n",
    "test = pd.read_csv('test_set.csv',encoding='UTF-8')\n",
    "\n",
    "# pd.set_option('display.max_colwidth',None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "data_copy = data.copy()\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     33000\n",
       "unique       11\n",
       "top         xho\n",
       "freq       3000\n",
       "Name: lang_id, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.lang_id.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy['length'] = data_copy['text'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>33000</td>\n",
       "      <td>33000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>11</td>\n",
       "      <td>29948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>xho</td>\n",
       "      <td>ngokwesekhtjheni yomthetho ophathelene nalokhu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3000</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lang_id                                               text\n",
       "count    33000                                              33000\n",
       "unique      11                                              29948\n",
       "top        xho  ngokwesekhtjheni yomthetho ophathelene nalokhu...\n",
       "freq      3000                                                 17"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _remove_punc(x):\n",
    "    \"\"\"\n",
    "    Function removes punctuation and ASCII code character\n",
    "    using string.punctuation function\n",
    "    \n",
    "    Args:\n",
    "        data: pandas dataframe\n",
    "    Return:\n",
    "        Dataframe: clean tweets\n",
    "    \"\"\"\n",
    "    x = re.sub(r'[-]',' ',x)\n",
    "    x = re.sub(r'[_]', ' ', x)\n",
    "    x = re.sub(r'[^\\w\\s]','',x)\n",
    "    x = re.sub('[0-9]+', '', x)\n",
    "    x = re.sub(r'[^\\x00-\\x7f]',r'', x)\n",
    "    return x\n",
    "\n",
    "#Apply the function to the dataset\n",
    "data_copy['clean_punc'] = data_copy['text'].apply(_remove_punc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _lower(x):\n",
    "\n",
    "    return x.lower()\n",
    "\n",
    "data_copy['lower'] = data_copy['clean_punc'].apply(_lower)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'could not'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nlppreprocess import NLP\n",
    "nlp = NLP()\n",
    "nlp.process('couldnt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mutis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "def remove_stopwords(x):\n",
    "    \"\"\"\n",
    "    Removes stop-words in the dataset to reduce noise\n",
    "\n",
    "    Args:\n",
    "        Args:\n",
    "        data: pandas dataframe\n",
    "    Return:\n",
    "        df:non-stop word\n",
    "    \"\"\"\n",
    "    stopwords = NLP(replace_words=True, remove_stopwords=True, \n",
    "                            remove_numbers=True, remove_punctuations=False) \n",
    "    x = stopwords.process(x)\n",
    "    return x\n",
    "    \n",
    "data_copy['Text_nonstop'] = data_copy['lower'].apply(lambda x: remove_stopwords(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _analyzer (x):\n",
    "    \"\"\"\n",
    "    Function combines all the cleaning operations\n",
    "    \"\"\"\n",
    "    x = _remove_punc(x)\n",
    "    x = _lower(x)\n",
    "    x = remove_stopwords(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>clean_punc</th>\n",
       "      <th>lower</th>\n",
       "      <th>Text_nonstop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "      <td>220</td>\n",
       "      <td>umgaqo siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "      <td>umgaqo siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "      <td>umgaqo siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "      <td>252</td>\n",
       "      <td>i dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "      <td>i dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "      <td>dha iya kuba nobulumko bokubeka umsebenzi naph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "      <td>264</td>\n",
       "      <td>the province of kwazulu natal department of tr...</td>\n",
       "      <td>the province of kwazulu natal department of tr...</td>\n",
       "      <td>province kwazulu natal department transport in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "      <td>217</td>\n",
       "      <td>o netefata gore o ba file dilo ka moka te le d...</td>\n",
       "      <td>o netefata gore o ba file dilo ka moka te le d...</td>\n",
       "      <td>o netefata gore o ba file dilo ka moka te le d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "      <td>239</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang_id                                               text  length  \\\n",
       "0     xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...     220   \n",
       "1     xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...     252   \n",
       "2     eng  the province of kwazulu-natal department of tr...     264   \n",
       "3     nso  o netefatša gore o ba file dilo ka moka tše le...     217   \n",
       "4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana...     239   \n",
       "\n",
       "                                          clean_punc  \\\n",
       "0  umgaqo siseko wenza amalungiselelo kumaziko ax...   \n",
       "1  i dha iya kuba nobulumko bokubeka umsebenzi na...   \n",
       "2  the province of kwazulu natal department of tr...   \n",
       "3  o netefata gore o ba file dilo ka moka te le d...   \n",
       "4  khomishini ya ndinganyiso ya mbeu yo ewa maana...   \n",
       "\n",
       "                                               lower  \\\n",
       "0  umgaqo siseko wenza amalungiselelo kumaziko ax...   \n",
       "1  i dha iya kuba nobulumko bokubeka umsebenzi na...   \n",
       "2  the province of kwazulu natal department of tr...   \n",
       "3  o netefata gore o ba file dilo ka moka te le d...   \n",
       "4  khomishini ya ndinganyiso ya mbeu yo ewa maana...   \n",
       "\n",
       "                                        Text_nonstop  \n",
       "0  umgaqo siseko wenza amalungiselelo kumaziko ax...  \n",
       "1  dha iya kuba nobulumko bokubeka umsebenzi naph...  \n",
       "2  province kwazulu natal department transport in...  \n",
       "3  o netefata gore o ba file dilo ka moka te le d...  \n",
       "4  khomishini ya ndinganyiso ya mbeu yo ewa maana...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cleaned'] = data['text'].apply(_analyzer)\n",
    "test['cleaned'] = test['text'].apply(_analyzer)\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Text Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting  features(X) and response(Y) variables\n",
    "X = data['cleaned']\n",
    "y = data['lang_id']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_test , y_train , y_test = train_test_split(X , y, stratify=y,\n",
    "                                                       test_size =0.4, \n",
    "                                                       random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing Models from scikit-learn\n",
    "\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, RidgeClassifier\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "alg = [LogisticRegression(random_state =42 , max_iter=5000) , \n",
    "       MultinomialNB(), LinearSVC(random_state=42), \n",
    "       SGDClassifier(random_state=42), RidgeClassifier(random_state=42)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer , TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _performace_assesment(*args , **kwargs):\n",
    "  model_stats = {}\n",
    "  for clf in alg:\n",
    "    model = Pipeline([('tfidf', TfidfVectorizer(stop_words = 'english', max_df=0.9, ngram_range=(1, 5), analyzer= 'char')),\n",
    "                      ('clf' , clf)\n",
    "                      ])\n",
    "    \n",
    "    model.fit(X_train, y_train) #Training\n",
    "    model_pred = model.predict(X_test) #Testing\n",
    "\n",
    "    # Dictionary of Models Performances\n",
    "    model_stats[clf.__class__.__name__] = {\n",
    "        'F1-Macro':metrics.f1_score(y_test, model_pred, average='macro'),\n",
    "        'F1-Accuracy':metrics.f1_score(y_test, model_pred, average='micro'),\n",
    "        'F1-Weighted':metrics.f1_score(y_test, model_pred, average='weighted')}\n",
    "  return pd.DataFrame.from_dict(model_stats, orient='index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1-Macro</th>\n",
       "      <th>F1-Accuracy</th>\n",
       "      <th>F1-Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.999394</td>\n",
       "      <td>0.999394</td>\n",
       "      <td>0.999394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifier</th>\n",
       "      <td>0.999167</td>\n",
       "      <td>0.999167</td>\n",
       "      <td>0.999167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.999167</td>\n",
       "      <td>0.999167</td>\n",
       "      <td>0.999167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.999091</td>\n",
       "      <td>0.999091</td>\n",
       "      <td>0.999091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.998183</td>\n",
       "      <td>0.998182</td>\n",
       "      <td>0.998183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    F1-Macro  F1-Accuracy  F1-Weighted\n",
       "MultinomialNB       0.999394     0.999394     0.999394\n",
       "RidgeClassifier     0.999167     0.999167     0.999167\n",
       "LinearSVC           0.999167     0.999167     0.999167\n",
       "SGDClassifier       0.999091     0.999091     0.999091\n",
       "LogisticRegression  0.998183     0.998182     0.998183"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance = _performace_assesment(alg , X_train , X_test , y_train , y_test)\n",
    "performance.to_csv('performance.csv')\n",
    "dataframe = pd.read_csv('performance.csv', index_col = 0)\n",
    "dataframe.sort_values('F1-Weighted', ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _param_tuning(*args , **kwargs):\n",
    "  best_params = {}\n",
    "\n",
    "  for clf in alg:\n",
    "    model = Pipeline([('tfidf', TfidfVectorizer(stop_words = 'english', max_df=0.9, ngram_range=(1, 5), analyzer= 'char')),\n",
    "                      ('clf' , clf)])\n",
    "    model.fit(X_train, y_train) #Training\n",
    "    \n",
    "    #Get models performing parameters\n",
    "    params = model.get_params()\n",
    "    model_name = clf.__class__.__name__  \n",
    "    model_name = {}\n",
    "    for key in params:\n",
    "      if key.startswith(\"clf\"):\n",
    "        if len(key) < 5:\n",
    "          model_name['model'] = params[key]\n",
    "        else:\n",
    "            model_name[key[5:]] = params[key]\n",
    "    best_params[clf.__class__.__name__] = model_name\n",
    "  return best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = _param_tuning(alg, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LogisticRegression': {'model': LogisticRegression(max_iter=5000, random_state=42),\n",
       "  'C': 1.0,\n",
       "  'class_weight': None,\n",
       "  'dual': False,\n",
       "  'fit_intercept': True,\n",
       "  'intercept_scaling': 1,\n",
       "  'l1_ratio': None,\n",
       "  'max_iter': 5000,\n",
       "  'multi_class': 'auto',\n",
       "  'n_jobs': None,\n",
       "  'penalty': 'l2',\n",
       "  'random_state': 42,\n",
       "  'solver': 'lbfgs',\n",
       "  'tol': 0.0001,\n",
       "  'verbose': 0,\n",
       "  'warm_start': False},\n",
       " 'MultinomialNB': {'model': MultinomialNB(),\n",
       "  'alpha': 1.0,\n",
       "  'class_prior': None,\n",
       "  'fit_prior': True},\n",
       " 'LinearSVC': {'model': LinearSVC(random_state=42),\n",
       "  'C': 1.0,\n",
       "  'class_weight': None,\n",
       "  'dual': True,\n",
       "  'fit_intercept': True,\n",
       "  'intercept_scaling': 1,\n",
       "  'loss': 'squared_hinge',\n",
       "  'max_iter': 1000,\n",
       "  'multi_class': 'ovr',\n",
       "  'penalty': 'l2',\n",
       "  'random_state': 42,\n",
       "  'tol': 0.0001,\n",
       "  'verbose': 0},\n",
       " 'SGDClassifier': {'model': SGDClassifier(random_state=42),\n",
       "  'alpha': 0.0001,\n",
       "  'average': False,\n",
       "  'class_weight': None,\n",
       "  'early_stopping': False,\n",
       "  'epsilon': 0.1,\n",
       "  'eta0': 0.0,\n",
       "  'fit_intercept': True,\n",
       "  'l1_ratio': 0.15,\n",
       "  'learning_rate': 'optimal',\n",
       "  'loss': 'hinge',\n",
       "  'max_iter': 1000,\n",
       "  'n_iter_no_change': 5,\n",
       "  'n_jobs': None,\n",
       "  'penalty': 'l2',\n",
       "  'power_t': 0.5,\n",
       "  'random_state': 42,\n",
       "  'shuffle': True,\n",
       "  'tol': 0.001,\n",
       "  'validation_fraction': 0.1,\n",
       "  'verbose': 0,\n",
       "  'warm_start': False},\n",
       " 'RidgeClassifier': {'model': RidgeClassifier(random_state=42),\n",
       "  'alpha': 1.0,\n",
       "  'class_weight': None,\n",
       "  'copy_X': True,\n",
       "  'fit_intercept': True,\n",
       "  'max_iter': None,\n",
       "  'normalize': 'deprecated',\n",
       "  'positive': False,\n",
       "  'random_state': 42,\n",
       "  'solver': 'auto',\n",
       "  'tol': 0.001}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vectorize = TfidfVectorizer(stop_words = 'english', max_df=0.9, ngram_range=(1, 5), analyzer= 'char')\n",
    "X_train = Vectorize.fit_transform(X_train)\n",
    "X_test = Vectorize.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True,\n",
    "                                   random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': MultinomialNB(),\n",
       " 'alpha': 1.0,\n",
       " 'class_prior': None,\n",
       " 'fit_prior': True}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params[alg[1].__class__.__name__]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = list(np.linspace(0.1,0.02,4))\n",
    "param_grid = dict(alpha=alpha)\n",
    "grid_search = GridSearchCV(estimator= model1,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='f1_weighted',\n",
    "                           cv=stratified_kfold,\n",
    "                           error_score=0,\n",
    "                           n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train)\n",
    "prediction = grid_search.predict(X_test)\n",
    "cv_score = grid_search.best_score_\n",
    "test_score = grid_search.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation score: 0.9996969686252897\n",
      "Test score: 0.9995455174533855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.04666666666666667)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Cross-validation score: {cv_score}')\n",
    "print(f'Test score: {test_score}')\n",
    "grid_search.best_params_    \n",
    "grid_search.best_estimator_\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying RidgeRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = RidgeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': RidgeClassifier(random_state=42),\n",
       " 'alpha': 1.0,\n",
       " 'class_weight': None,\n",
       " 'copy_X': True,\n",
       " 'fit_intercept': True,\n",
       " 'max_iter': None,\n",
       " 'normalize': 'deprecated',\n",
       " 'positive': False,\n",
       " 'random_state': 42,\n",
       " 'solver': 'auto',\n",
       " 'tol': 0.001}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params[alg[4].__class__.__name__]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = list(np.linspace(0.15,0.4, 5))\n",
    "param_grid = dict(alpha=alpha)\n",
    "grid_search = GridSearchCV(estimator= model2,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='f1_weighted',\n",
    "                           cv=stratified_kfold,\n",
    "                           error_score=0,\n",
    "                           n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train)\n",
    "prediction = grid_search.predict(X_test)\n",
    "cv_score = grid_search.best_score_\n",
    "test_score = grid_search.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation score: 0.9994949477404799\n",
      "Test score: 0.9990909717224429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RidgeClassifier(alpha=0.275)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Cross-validation score: {cv_score}')\n",
    "print(f'Test score: {test_score}')\n",
    "grid_search.best_params_    \n",
    "grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.pipeline import make_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['cleaned']\n",
    "y = data['lang_id']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test , y_train , y_test = train_test_split(X, y,  stratify=y, test_size=0.4, random_state =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(stop_words = 'english', max_df=0.9, ngram_range=(2, 6), analyzer= 'char')\n",
    "X_train = vect.fit_transform(X_train)\n",
    "X_test = vect.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiNB1 = MultinomialNB(alpha=0.1)\n",
    "multiNB2 = MultinomialNB(alpha=0.1)\n",
    "\n",
    "estimators = [('multiNB1', multiNB1), ('multiNB2', multiNB2)]\n",
    "final_est = RidgeClassifier(alpha=0.2125)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_NB2 = StackingClassifier(estimators = estimators,\n",
    "                           final_estimator = final_est,\n",
    "                           passthrough = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('multiNB1', MultinomialNB(alpha=0.1)),\n",
       "                               ('multiNB2', MultinomialNB(alpha=0.1))],\n",
       "                   final_estimator=RidgeClassifier(alpha=0.2125),\n",
       "                   passthrough=True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking_NB2.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = stacking_NB2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1-Macro</th>\n",
       "      <th>F1-Accuracy</th>\n",
       "      <th>F1-Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>StackingClassifier</th>\n",
       "      <td>0.999773</td>\n",
       "      <td>0.999773</td>\n",
       "      <td>0.999773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    F1-Macro  F1-Accuracy  F1-Weighted\n",
       "StackingClassifier  0.999773     0.999773     0.999773"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_stats = {}\n",
    "model_stats[stacking_NB2.__class__.__name__] = {\n",
    "        'F1-Macro':metrics.f1_score(y_test, pred, average='macro'),\n",
    "        'F1-Accuracy':metrics.f1_score(y_test, pred, average='micro'),\n",
    "        'F1-Weighted':metrics.f1_score(y_test, pred, average='weighted')}\n",
    "pd.DataFrame.from_dict(model_stats, orient='index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer(ngram_range=(3,7), analyzer= 'char')\n",
    "X_train , X_test , y_train , y_test = train_test_split(X, y, stratify=y,test_size=0.05, random_state =1)\n",
    "X_train = count_vec.fit_transform(X_train)\n",
    "X_test = count_vec.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiNB1 = MultinomialNB(alpha=0.1)\n",
    "multiNB2 = MultinomialNB(alpha=0.1)\n",
    "multiNB3 = MultinomialNB(alpha=0.1)\n",
    "\n",
    "estimators = [('multiNB1', multiNB1), ('multiNB2', multiNB2), ('multiNB3', multiNB3)]\n",
    "final_est = RidgeClassifier(alpha=0.2125)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_NB3 = StackingClassifier(estimators = estimators,\n",
    "                           final_estimator = final_est,\n",
    "                           passthrough = True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('multiNB1', MultinomialNB(alpha=0.1)),\n",
       "                               ('multiNB2', MultinomialNB(alpha=0.1)),\n",
       "                               ('multiNB3', MultinomialNB(alpha=0.1))],\n",
       "                   final_estimator=RidgeClassifier(alpha=0.2125),\n",
       "                   passthrough=True)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking_NB3.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = stacking_NB3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1-Macro</th>\n",
       "      <th>F1-Accuracy</th>\n",
       "      <th>F1-Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>StackingClassifier</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    F1-Macro  F1-Accuracy  F1-Weighted\n",
       "StackingClassifier       1.0          1.0          1.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_stats = {}\n",
    "model_stats[stacking_NB3.__class__.__name__] = {\n",
    "        'F1-Macro':metrics.f1_score(y_test, pred, average='macro'),\n",
    "        'F1-Accuracy':metrics.f1_score(y_test, pred, average='micro'),\n",
    "        'F1-Weighted':metrics.f1_score(y_test, pred, average='weighted')}\n",
    "pd.DataFrame.from_dict(model_stats, orient='index')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = test['cleaned']\n",
    "Vectorize = vect.transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['lang_id'] = stacking_NB2.predict(Vectorize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lang_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>tsn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>nbl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ssw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>afr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5677</th>\n",
       "      <td>5678</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5678</th>\n",
       "      <td>5679</td>\n",
       "      <td>nso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5679</th>\n",
       "      <td>5680</td>\n",
       "      <td>sot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5680</th>\n",
       "      <td>5681</td>\n",
       "      <td>sot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5681</th>\n",
       "      <td>5682</td>\n",
       "      <td>nbl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5682 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index lang_id\n",
       "0         1     tsn\n",
       "1         2     nbl\n",
       "2         3     ven\n",
       "3         4     ssw\n",
       "4         5     afr\n",
       "...     ...     ...\n",
       "5677   5678     eng\n",
       "5678   5679     nso\n",
       "5679   5680     sot\n",
       "5680   5681     sot\n",
       "5681   5682     nbl\n",
       "\n",
       "[5682 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = test[['index', 'lang_id']]\n",
    "submission.to_csv('Submission.csv',index=False)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       mmasepala fa maemo kgethegileng letlelela kgat...\n",
       "1       uzakwaziswa ngokufaneleko nakungafuneka eminye...\n",
       "2               tshivhumbeo tshi fana na ngano dza vhathu\n",
       "3       kube inja nelikati betingevakala kutsi titsini...\n",
       "4                            winste op buitelandse valuta\n",
       "                              ...                        \n",
       "5677                      you mark your ballot in private\n",
       "5678    ge o ka kgetha ka bowena go se omie mofani ka ...\n",
       "5679    e ka kopo etsa kgetho ya hao ka hloko hobane h...\n",
       "5680    tb ke bokudi ba pmb mme morero o tla lefella t...\n",
       "5681                 vakatjhela iwebhusayidi yethu ku www\n",
       "Name: cleaned, Length: 5682, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
